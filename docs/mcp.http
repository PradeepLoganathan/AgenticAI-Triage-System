@baseUrl = http://localhost:9100
@json = application/json

# About this file
# - These JSON-RPC calls hit the in-app MCP endpoint (`POST {{baseUrl}}/mcp`).
# - The MCP server here is a reference that reads from classpath files.
# - In a real setup, this MCP endpoint should WRAP your observability backends.
#
# Typical backends to wrap:
# - Logs: Grafana Loki, Elasticsearch (ELK/OpenSearch), Splunk, CloudWatch Logs, GCP Cloud Logging.
# - Metrics: Prometheus/Thanos/VictoriaMetrics, Datadog, New Relic, CloudWatch Metrics, GCP Cloud Monitoring.
#
# Mapping ideas:
# - fetch_logs(service, lines, range):
#   - Loki: `{app="{{service}}"}` + tail over `range`, limit = `lines`.
#   - Elasticsearch: index pattern per service, `query_string` with time filter (range â†’ @timestamp).
#   - Splunk: `search index=prod service={{service}} earliest=-{{range}} | head {{lines}}`
#   - CloudWatch Logs: Log group `/aws/ecs/{{service}}`; FilterLogEvents with `startTime`/`endTime` and `limit=lines`.
# - query_metrics(expr, range):
#   - Prometheus: PromQL, e.g. `rate(http_requests_total{service="checkout",code=~"5.."}[5m])` over `range`.
#   - Datadog: timeseries, e.g. `avg:errors.rate{service:checkout}.rollup(60)`; map `range` to from/to.
#   - CloudWatch Metrics: Map `expr` to (Namespace, MetricName, Dimensions), use `GetMetricData` over `range`.
#   - New Relic/GCP: Map `expr` to NRQL/Monitoring filters respectively.

### fetch_logs: payment-service, 100 lines, 1h
# Example real-world mapping:
# - Loki: `{app="payment-service"}` over last 1h, limit 100
# - Elasticsearch: index=logs-*, query="service:payment-service AND @timestamp:[now-1h TO now]" size=100 sort=desc
POST {{baseUrl}}/mcp
Content-Type: {{json}}

{
  "jsonrpc": "2.0",
  "id": "logs-1",
  "method": "call_tool",
  "params": {
    "name": "fetch_logs",
    "arguments": {
      "service": "payment-service",
      "lines": 100,
      "range": "1h"
    }
  }
}

### fetch_logs: checkout-service, 50 lines, 30m
# Example real-world mapping:
# - Splunk: `search index=prod service=checkout earliest=-30m | head 50`
# - CloudWatch Logs: group=/aws/ecs/checkout, limit=50, startTime=now-30m
POST {{baseUrl}}/mcp
Content-Type: {{json}}

{
  "jsonrpc": "2.0",
  "id": "logs-2",
  "method": "call_tool",
  "params": {
    "name": "fetch_logs",
    "arguments": {
      "service": "checkout-service",
      "lines": 50,
      "range": "30m"
    }
  }
}

### fetch_logs: using stringified arguments (supported)
# Stringified `arguments` are accepted by the endpoint as well
POST {{baseUrl}}/mcp
Content-Type: {{json}}

{
  "jsonrpc": "2.0",
  "id": "logs-3",
  "method": "call_tool",
  "params": {
    "name": "fetch_logs",
    "arguments": "{\"service\":\"user-service\",\"lines\":50,\"range\":\"30m\"}"
  }
}

### query_metrics: errors:rate5m over 1h
# Example real-world mapping:
# - Prometheus: `rate(http_requests_total{service="payment-service",code=~"5.."}[5m])`
# - Datadog: `avg:service.errors{service:payment-service}.rollup(60)`
POST {{baseUrl}}/mcp
Content-Type: {{json}}

{
  "jsonrpc": "2.0",
  "id": "metrics-1",
  "method": "call_tool",
  "params": {
    "name": "query_metrics",
    "arguments": {
      "expr": "errors:rate5m",
      "range": "1h"
    }
  }
}

### query_metrics: latency p99 over 1h
# Example real-world mapping:
# - Prometheus: `histogram_quantile(0.99, sum(rate(http_request_duration_seconds_bucket{service="api"}[5m])) by (le))`
# - CloudWatch Metrics: MetricName=TargetResponseTime (ALB), Dimension=TargetGroup, Statistic=p99
POST {{baseUrl}}/mcp
Content-Type: {{json}}

{
  "jsonrpc": "2.0",
  "id": "metrics-2",
  "method": "call_tool",
  "params": {
    "name": "query_metrics",
    "arguments": {
      "expr": "latency:p99",
      "range": "1h"
    }
  }
}

### query_metrics: cpu utilization over 2h
# Example real-world mapping:
# - Prometheus: `avg(rate(container_cpu_usage_seconds_total{service="user-service"}[5m])) by (service)`
# - CloudWatch Metrics: Namespace=ECS/ContainerInsights, MetricName=CpuUtilized, Dimensions=Cluster/Service
POST {{baseUrl}}/mcp
Content-Type: {{json}}

{
  "jsonrpc": "2.0",
  "id": "metrics-3",
  "method": "call_tool",
  "params": {
    "name": "query_metrics",
    "arguments": {
      "expr": "cpu:utilization",
      "range": "2h"
    }
  }
}
